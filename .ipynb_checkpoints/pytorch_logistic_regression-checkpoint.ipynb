{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. Logistic Regression with PyTorch\n",
    "## 1. About Logistic Regression\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### 1.1 Logistic Regression Basics\n",
    "\n",
    "#### Classification algorithm\n",
    "- Example: Spam vs No Spam\n",
    "    - Input: Bunch of words\n",
    "    - Output: Probability spam or not\n",
    "\n",
    "#### Basic Comparison\n",
    "- **Linear regression**\n",
    "    - Output: numeric value given inputs\n",
    "- **Logistic regression**:\n",
    "    - Output: probability [0, 1] given input belonging to a class\n",
    "    \n",
    "    \n",
    "#### Input/Output Comparison\n",
    "- **Linear regression: Multiplication**\n",
    "    - Input: [1]\n",
    "        - Output: 2\n",
    "    - Input: [2]\n",
    "        - Output: 4\n",
    "    - Trying to model the relationship `y = 2x`\n",
    "- **Logistic regression: Spam**\n",
    "    - Input: \"Sign up to get 1 million dollars by tonight\"\n",
    "        - Output: p = 0.8\n",
    "    - Input: \"This is a receipt for your recent purchase with Amazon\"\n",
    "        - Output: p = 0.3\n",
    "    - **p: probability it is spam**\n",
    "        \n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Problems of Linear Regression\n",
    "- Example\n",
    "    - Fever\n",
    "    - **Input**: temperature\n",
    "    - **Output**: fever or no fever\n",
    "- Remember\n",
    "    - **Linear regression**: minimize error between points and line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "x = [1, 5, 10, 10, 25, 50, 70, 75, 100]\n",
    "y = [0, 0, 0, 0, 0, 1, 1, 1, 1]\n",
    "\n",
    "colors = np.random.rand(len(x))\n",
    "plt.plot(np.unique(x), np.poly1d(np.polyfit(x, y, 1))(np.unique(x)))\n",
    "plt.ylabel(\"Fever\")\n",
    "plt.xlabel(\"Temperature\")\n",
    "\n",
    "plt.scatter(x, y, c=colors, alpha=0.5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Linear Regression Problem 1**\n",
    "<br> Fever value can go negative (below 0) and positive (above 1).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "x = [1, 5, 10, 10, 25, 50, 70, 75, 300]\n",
    "y = [0, 0, 0, 0, 0, 1, 1, 1, 1]\n",
    "\n",
    "colors = np.random.rand(len(x))\n",
    "plt.plot(np.unique(x), np.poly1d(np.polyfit(x, y, 1))(np.unique(x)))\n",
    "plt.ylabel(\"Fever\")\n",
    "plt.xlabel(\"Temperature\")\n",
    "\n",
    "plt.scatter(x, y, c=colors, alpha=0.5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Linear Regression Problem 2**\n",
    "<br> Fever points not predicted with outliers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Logistic Regression In-Depth\n",
    "\n",
    "#### Predicting Probability\n",
    "- Linear regression doesn't work\n",
    "- Instead of predicting direct values: **predict probability**\n",
    "\n",
    "<img src=\"./img/cross_entropy_final_4.png\" alt=\"deeplearningwizard\" style=\"width: 900px;\"/>\n",
    "\n",
    "#### Logistic Function $g()$ \n",
    "- Two-class logistic regression\n",
    "- $ y = A x + b$\n",
    "- $ g(y) = A x + b $\n",
    "- $g(y) = \\frac {1} {1 + e^{-y}} = \\frac {1} {1 + e^{-(A x + b)}}$\n",
    "- $g(y)$ = Estimated probability that $y = 1$ given $x$\n",
    "\n",
    "\n",
    "#### Softmax Function $g()$ \n",
    "- Multi-class logistic regression\n",
    "- Generalization of logistic function\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cross Entropy Function $D()$\n",
    "- $D(S, L) = L log S - (1-L)log(1-S)$\n",
    "    - If L = 0 (label)\n",
    "        - $D(S, 0) = - log(1-S)$\n",
    "            - $- log(1-S)$: less positive if $S \\longrightarrow 0 $\n",
    "            - $- log(1-S)$: more positive if $S \\longrightarrow 1 $ (BIGGER LOSS)\n",
    "    - If L = 1 (label)\n",
    "        - $D(S, 1) = log S$\n",
    "            - $logS$: less negative if $S \\longrightarrow 1 $\n",
    "            - $logS$: more negative if $S \\longrightarrow 0 $ (BIGGER LOSS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](img/AnalysisLogisticReg.jpeg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0000050000287824e-05\n",
      "11.51292546497478\n",
      "-1.0000050000287824e-05\n",
      "-11.512925464970229\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "print(-math.log(1 - 0.00001))\n",
    "print(-math.log(1 - 0.99999))\n",
    "\n",
    "print(math.log(0.99999))\n",
    "print(math.log(0.00001))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cross Entropy Loss $L$\n",
    "- Goal: Minimizing Cross Entropy Loss\n",
    "- $ L = \\frac {1}{N} \\sum_i D(g(Ax_i + b), L_i)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Building a Logistic Regression Model with PyTorch\n",
    "\n",
    "<img src=\"./img/lr2.png\" alt=\"deeplearningwizard\" style=\"width: 900px;\"/>\n",
    "\n",
    "### Steps\n",
    "- Step 1: Load Dataset\n",
    "- Step 2: Make Dataset Iterable\n",
    "- Step 3: Create Model Class\n",
    "- Step 4: Instantiate Model Class\n",
    "- Step 5: Instantiate Loss Class\n",
    "- Step 6: Instantiate Optimizer Class\n",
    "- Step 7: Train Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1a: Loading MNIST Train Dataset\n",
    "**Images from 1 to 9**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as dsets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = dsets.MNIST(root='./data', \n",
    "                            train=True, \n",
    "                            transform=transforms.ToTensor(),\n",
    "                            download=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60000"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0118, 0.0706, 0.0706, 0.0706,\n",
       "           0.4941, 0.5333, 0.6863, 0.1020, 0.6510, 1.0000, 0.9686, 0.4980,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.1176, 0.1412, 0.3686, 0.6039, 0.6667, 0.9922, 0.9922, 0.9922,\n",
       "           0.9922, 0.9922, 0.8824, 0.6745, 0.9922, 0.9490, 0.7647, 0.2510,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.1922,\n",
       "           0.9333, 0.9922, 0.9922, 0.9922, 0.9922, 0.9922, 0.9922, 0.9922,\n",
       "           0.9922, 0.9843, 0.3647, 0.3216, 0.3216, 0.2196, 0.1529, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0706,\n",
       "           0.8588, 0.9922, 0.9922, 0.9922, 0.9922, 0.9922, 0.7765, 0.7137,\n",
       "           0.9686, 0.9451, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.3137, 0.6118, 0.4196, 0.9922, 0.9922, 0.8039, 0.0431, 0.0000,\n",
       "           0.1686, 0.6039, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0549, 0.0039, 0.6039, 0.9922, 0.3529, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.5451, 0.9922, 0.7451, 0.0078, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0431, 0.7451, 0.9922, 0.2745, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.1373, 0.9451, 0.8824, 0.6275,\n",
       "           0.4235, 0.0039, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.3176, 0.9412, 0.9922,\n",
       "           0.9922, 0.4667, 0.0980, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.1765, 0.7294,\n",
       "           0.9922, 0.9922, 0.5882, 0.1059, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0627,\n",
       "           0.3647, 0.9882, 0.9922, 0.7333, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.9765, 0.9922, 0.9765, 0.2510, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.1804, 0.5098,\n",
       "           0.7176, 0.9922, 0.9922, 0.8118, 0.0078, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.1529, 0.5804, 0.8980, 0.9922,\n",
       "           0.9922, 0.9922, 0.9804, 0.7137, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0941, 0.4471, 0.8667, 0.9922, 0.9922, 0.9922,\n",
       "           0.9922, 0.7882, 0.3059, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0902, 0.2588, 0.8353, 0.9922, 0.9922, 0.9922, 0.9922, 0.7765,\n",
       "           0.3176, 0.0078, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0706, 0.6706,\n",
       "           0.8588, 0.9922, 0.9922, 0.9922, 0.9922, 0.7647, 0.3137, 0.0353,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.2157, 0.6745, 0.8863, 0.9922,\n",
       "           0.9922, 0.9922, 0.9922, 0.9569, 0.5216, 0.0431, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.5333, 0.9922, 0.9922, 0.9922,\n",
       "           0.8314, 0.5294, 0.5176, 0.0627, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000]]]),\n",
       " 5)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tuple"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(train_dataset[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 28, 28])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Input Matrix\n",
    "train_dataset[0][0].size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Label\n",
    "train_dataset[0][1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Displaying MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline  \n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 28, 28)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset[0][0].numpy().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_img = train_dataset[0][0].numpy().reshape(28, 28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f82ae0b9850>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(show_img, cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Label\n",
    "train_dataset[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_img = train_dataset[1][0].numpy().reshape(28, 28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f82ae02c710>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(show_img, cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Label\n",
    "train_dataset[1][1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1b: Loading MNIST Test Dataset\n",
    "- Show our algorithm works beyond the data we have trained on.\n",
    "- Out-of-sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = dsets.MNIST(root='./data', \n",
    "                           train=False, \n",
    "                           transform=transforms.ToTensor())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tuple"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(test_dataset[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 28, 28])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Image matrix\n",
    "test_dataset[0][0].size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f82ad82a0d0>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_img = test_dataset[0][0].numpy().reshape(28, 28)\n",
    "plt.imshow(show_img, cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Label\n",
    "test_dataset[0][1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Make Dataset Iterable\n",
    "- Aim: make the dataset iterable\n",
    "- **totaldata**: 60000\n",
    "- **minibatch**: 100\n",
    "    - Number of examples in 1 iteration\n",
    "- **iterations**: 3000\n",
    "    - 1 iteration: one mini-batch forward & backward pass\n",
    "- **epochs**\n",
    "    - 1 epoch: running through the whole dataset once\n",
    "    - $epochs = iterations \\div \\frac{totaldata}{minibatch} = 3000 \\div \\frac{60000}{100} = 5 $\n",
    "    \n",
    "### Explaination Hao\n",
    "\n",
    "    Training set 60000 in total, I divid training set into equal size mini parts (100 for each mini-part)\n",
    "    One training time, I put minibatch size (100) images to train model. So, I should cycle 60 000 / 100 = 600 times(loops) to iterate entire training dataset. \n",
    "    I personally want to train totally the model 3000 times(loops). Hence, I need 5 epoches to reach 3000 times.\n",
    "- $epochs = iterations \\div \\frac{totaldata}{minibatch} = 3000 \\div \\frac{60000}{100} = 5 $             "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60000"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_iters = 3000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_epochs = n_iters / (len(train_dataset) / batch_size)\n",
    "num_epochs = int(num_epochs)\n",
    "num_epochs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create Iterable Object: Training Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, \n",
    "                                           batch_size=batch_size, \n",
    "                                           shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check Iterability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hao/anaconda3/envs/open-mmlab/lib/python3.7/site-packages/ipykernel_launcher.py:2: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated since Python 3.3,and in 3.9 it will stop working\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import collections\n",
    "isinstance(train_loader, collections.Iterable)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create Iterable Object: Testing Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterable object\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_dataset, \n",
    "                                          batch_size=batch_size, \n",
    "                                          shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check Iterability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "isinstance(test_loader, collections.Iterable)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Main Aim: Iterate Through Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_1 = np.ones((28, 28))\n",
    "img_2 = np.ones((28, 28))\n",
    "lst = [img_1, img_2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(28, 28)\n",
      "(28, 28)\n"
     ]
    }
   ],
   "source": [
    "# Need to iterate\n",
    "# Think of numbers as the images\n",
    "for i in lst:\n",
    "    print(i.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Building Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Same as linear regression! \n",
    "class LogisticRegressionModel(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim):\n",
    "        super(LogisticRegressionModel, self).__init__()\n",
    "        self.linear = nn.Linear(input_dim, output_dim)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        out = self.linear(x)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Instantiate Model Class\n",
    "- Input dimension: \n",
    "    - Size of image\n",
    "    - $28 \\times 28 = 784$\n",
    "- Output dimension: 10\n",
    "    - 0, 1, 2, 3, 4, 5, 6, 7, 8, 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 28, 28])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Size of images\n",
    "train_dataset[0][0].size()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dim = 28*28\n",
    "output_dim = 10\n",
    "\n",
    "model = LogisticRegressionModel(input_dim, output_dim)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5: Instantiate Loss Class\n",
    "- **Logistic Regression**: Cross Entropy Loss\n",
    "    - _Linear Regression: MSE_\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### What happens in `nn.CrossEntropyLoss()`?\n",
    "- Computes softmax (logistic/softmax function)\n",
    "- Computes cross entropy\n",
    "\n",
    "<img src=\"./img/cross_entropy_final_4.png\" alt=\"deeplearningwizard\" style=\"width: 900px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 6: Instantiate Optimizer Class\n",
    "- Simplified equation\n",
    "    - $\\theta = \\theta - \\eta \\cdot \\nabla_\\theta $\n",
    "        - $\\theta$: parameters (our variables)\n",
    "        - $\\eta$: learning rate (how fast we want to learn)\n",
    "        - $\\nabla_\\theta$: parameters' gradients\n",
    "- Even simplier equation\n",
    "    - `parameters = parameters - learning_rate * parameters_gradients`\n",
    "    - **At every iteration, we update our model's parameters**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.001\n",
    "\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameters In-Depth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<generator object Module.parameters at 0x7f82fea86bd0>\n",
      "2\n",
      "torch.Size([10, 784])\n",
      "torch.Size([10])\n"
     ]
    }
   ],
   "source": [
    "print(model.parameters())\n",
    "\n",
    "print(len(list(model.parameters())))\n",
    "\n",
    "# FC 1 Parameters\n",
    "# Because y = Ax + b, dimension of y is 10 (ten numbers of labels). So, dimension of A is 10*(784=28*28).\n",
    "\n",
    "print(list(model.parameters())[0].size())\n",
    "\n",
    "# FC 1 Bias Parameters\n",
    "# Because y = Ax + b, dimension of b is 10 (ten numbers of labels). So, dimension of bias b is 10.\n",
    "\n",
    "print(list(model.parameters())[1].size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Quick Dot Product Review\n",
    "- Example 1: **dot product**\n",
    "    - $A: (100, 10)$\n",
    "    - $B: (10, 1)$\n",
    "    - $A \\cdot B = (100, 10) \\cdot (10, 1) = (100, 1)$\n",
    "- Example 2: **dot product**\n",
    "    - $A: (50, 5)$\n",
    "    - $B: (5, 2)$\n",
    "    - $A \\cdot B = (50, 5) \\cdot (5, 2) = (50, 2)$\n",
    "- Example 3: **element-wise addition**\n",
    "    - $A: (10, 1)$\n",
    "    - $B: (10, 1)$\n",
    "    - $A + B = (10, 1)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./images/lr_params2.png\" alt=\"deeplearningwizard\" style=\"width: 900px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 7: Train Model\n",
    "- Process \n",
    "    1. Convert inputs/labels to variables\n",
    "    2. Clear gradient buffets\n",
    "    3. Get output given inputs \n",
    "    4. Get loss\n",
    "    5. Get gradients w.r.t. parameters\n",
    "    6. Update parameters using gradients\n",
    "        - `parameters = parameters - learning_rate * parameters_gradients`\n",
    "    7. REPEAT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 500. Loss: 1.8431134223937988. Accuracy: 64\n",
      "Iteration: 1000. Loss: 1.5304043292999268. Accuracy: 74\n",
      "Iteration: 1500. Loss: 1.2898565530776978. Accuracy: 78\n",
      "Iteration: 2000. Loss: 1.1771576404571533. Accuracy: 80\n",
      "Iteration: 2500. Loss: 1.0459070205688477. Accuracy: 81\n",
      "Iteration: 3000. Loss: 1.034541368484497. Accuracy: 82\n"
     ]
    }
   ],
   "source": [
    "iter = 0\n",
    "for epoch in range(int(num_epochs)):\n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "        # Load images as Variable\n",
    "        images = images.view(-1, 28*28).requires_grad_()\n",
    "        labels = labels\n",
    "        \n",
    "        # Clear gradients w.r.t. parameters\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Forward pass to get output/logits\n",
    "        # Output: 100 x 10\n",
    "        # Apply Linear Regression:\n",
    "        #    Output(100 x 10) =   X(100x784) * A(784x10) + Bias(100x10)\n",
    "        outputs = model(images)\n",
    "        \n",
    "        # Calculate Loss: softmax --> cross entropy loss\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        # Getting gradients w.r.t. parameters\n",
    "        loss.backward()\n",
    "        \n",
    "        # Updating parameters\n",
    "        optimizer.step()\n",
    "        \n",
    "        iter += 1\n",
    "        \n",
    "        if iter % 500 == 0:\n",
    "            # Calculate Accuracy         \n",
    "            correct = 0\n",
    "            total = 0\n",
    "            # Iterate through test dataset\n",
    "            for images, labels in test_loader:\n",
    "                # Load images to a Torch Variable\n",
    "                images = images.view(-1, 28*28).requires_grad_()\n",
    "                \n",
    "                # Forward pass to get output/logits\n",
    "                # Output: 100 x 10\n",
    "                # Apply Linear Regression:\n",
    "                # Output(100 x 10) =   X(100x784) * A(784x10) + Bias(100x10)\n",
    "                outputs = model(images)\n",
    "                \n",
    "                # Get predictions from the maximum value\n",
    "                # predicted.shape = 100\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                \n",
    "                # Total number of labels\n",
    "                # labels.size = 100 (minibatch)\n",
    "                total += labels.size(0)\n",
    "                \n",
    "                # Total correct predictions\n",
    "                correct += (predicted == labels).sum()\n",
    "            \n",
    "            accuracy = 100 * correct / total\n",
    "            \n",
    "            # Print Loss\n",
    "            print('Iteration: {}. Loss: {}. Accuracy: {}'.format(iter, loss.item(), accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#### Explaination for:\n",
    "        outputs = model(images)\n",
    "        ...\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        \n",
    "<img src=\"./img/TestSetMaxIndex.jpeg\" alt=\"deeplearningwizard\" style=\"width: 900px;\"/>\n",
    "\n",
    "#### Break Down Accuracy Calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OUTPUTS\n",
      "tensor([[-3.2474e-01, -1.1798e+00, -4.4596e-01, -5.2345e-02,  1.1184e-01,\n",
      "         -3.2556e-01, -1.1478e+00,  2.7933e+00, -1.1076e-01,  8.2766e-01],\n",
      "        [ 1.3074e-01, -1.3611e-01,  1.6994e+00,  8.9703e-01, -1.9703e+00,\n",
      "          4.8143e-01,  1.0312e+00, -1.9217e+00,  4.3099e-01, -1.5655e+00],\n",
      "        [-1.0025e+00,  2.2451e+00,  1.6994e-01, -1.9945e-02, -7.4794e-01,\n",
      "         -4.0712e-01, -2.5078e-01, -2.9566e-01,  7.6681e-03, -3.5111e-01],\n",
      "        [ 2.8574e+00, -2.3052e+00, -1.2945e-01, -2.9137e-01, -9.2864e-01,\n",
      "          6.3847e-01,  1.1942e+00,  1.2938e-01, -4.9755e-01, -1.7095e-01],\n",
      "        [-2.2786e-01, -2.0134e+00,  4.7451e-01, -7.5448e-01,  1.8027e+00,\n",
      "         -4.2293e-01,  1.3031e-01,  3.7236e-01, -6.3359e-02,  9.2727e-01],\n",
      "        [-1.4311e+00,  2.7082e+00,  7.4501e-02,  5.4267e-02, -7.9735e-01,\n",
      "         -4.7227e-01, -8.4466e-01, -1.9187e-01,  2.4395e-01, -2.4181e-01],\n",
      "        [-1.3355e+00, -1.2840e+00, -8.8745e-01,  1.5185e-01,  1.5700e+00,\n",
      "          1.3163e-01, -8.7290e-01,  6.8040e-01,  4.1765e-01,  8.1072e-01],\n",
      "        [-1.4751e+00, -6.2738e-01, -7.1868e-01, -6.6004e-02,  6.8260e-01,\n",
      "          1.8793e-01,  3.7638e-01, -7.3197e-02,  8.1214e-02,  1.2237e+00],\n",
      "        [ 8.7175e-02, -6.3621e-01,  7.2153e-01, -1.6116e+00,  6.3956e-01,\n",
      "          8.1233e-02,  3.0269e-01, -9.9281e-01, -7.7039e-02,  4.6670e-02],\n",
      "        [-6.6050e-01, -6.9532e-01, -1.1813e+00, -1.2943e+00,  8.3586e-01,\n",
      "         -2.2681e-01, -5.9178e-01,  1.7166e+00, -2.4886e-01,  1.6350e+00],\n",
      "        [ 3.1533e+00, -1.7213e+00,  6.0644e-01,  1.0329e+00, -8.4585e-01,\n",
      "          1.0657e+00, -5.6597e-01, -1.5168e+00,  5.9689e-01, -1.6680e+00],\n",
      "        [ 7.5770e-01, -3.8127e-01,  8.8214e-01, -2.9324e-01,  3.3376e-01,\n",
      "         -3.1678e-01,  6.6738e-01, -8.9443e-01,  8.8578e-02, -3.4955e-01],\n",
      "        [-8.7445e-01, -1.6223e+00, -8.9283e-01, -9.8374e-01,  1.3746e+00,\n",
      "         -2.4806e-01, -4.7918e-01,  8.9706e-01,  2.3942e-01,  1.9301e+00],\n",
      "        [ 3.1080e+00, -2.2211e+00, -1.4342e-01, -3.0710e-01, -4.3775e-01,\n",
      "          7.7295e-01, -4.1333e-01, -5.2645e-01,  4.2569e-01,  1.7300e-01],\n",
      "        [-1.4338e+00,  2.6199e+00, -1.2447e-01,  3.6179e-01, -1.2000e+00,\n",
      "         -9.4543e-02, -4.3756e-03, -4.3352e-01,  1.9890e-01, -3.7609e-01],\n",
      "        [ 4.4441e-01, -8.7268e-01, -2.5097e-01,  1.4154e+00, -4.7455e-01,\n",
      "          8.8880e-01, -1.7599e-01, -5.5084e-01,  4.7271e-01, -9.9476e-01],\n",
      "        [-4.8990e-01, -2.0040e+00,  1.9349e-02, -7.9908e-01,  1.4375e+00,\n",
      "         -6.1462e-01, -2.4646e-01,  7.5934e-01,  4.0446e-02,  1.5916e+00],\n",
      "        [ 2.0592e-01, -1.5318e+00, -5.7025e-01,  4.2424e-01, -2.3974e-01,\n",
      "         -1.4763e-01, -8.5424e-01,  2.5689e+00, -3.6845e-01,  5.1986e-01],\n",
      "        [-9.0257e-01, -4.6796e-01, -1.6463e-01,  1.1766e+00, -2.6678e-01,\n",
      "          3.7508e-01,  5.5991e-01, -4.3237e-01,  7.5697e-02, -7.2217e-01],\n",
      "        [-9.1358e-01, -1.7743e+00, -4.2006e-01, -1.5744e-01,  1.9198e+00,\n",
      "         -5.3505e-02, -1.4951e-01,  5.9387e-03, -5.0348e-02,  1.3228e+00],\n",
      "        [-9.2739e-01, -3.9368e-01, -1.4699e+00, -7.3132e-03,  3.7640e-01,\n",
      "          1.0280e-01, -1.4879e+00,  1.7347e+00,  1.9027e-01,  1.4252e+00],\n",
      "        [-7.7961e-01, -1.7342e+00,  2.7797e-02,  3.1258e-01,  2.2152e-01,\n",
      "          4.0296e-01,  2.2963e+00, -1.4896e+00,  1.4542e-01,  4.4059e-02],\n",
      "        [-4.4997e-01,  3.6328e-01,  5.3903e-01, -8.4563e-01,  7.9947e-01,\n",
      "         -9.2608e-01,  9.6266e-01,  7.0391e-02, -4.2761e-01, -1.3804e-01],\n",
      "        [-3.6382e-01, -9.6502e-01, -7.2034e-01,  1.9627e-01, -3.1766e-01,\n",
      "          1.2461e+00,  2.9213e-01, -9.6767e-01,  6.7980e-01,  2.6504e-02],\n",
      "        [-7.4891e-01, -1.1340e+00, -4.3941e-02, -1.1960e-01,  1.1782e+00,\n",
      "         -4.0932e-01, -2.2463e-01,  3.0246e-01, -4.0533e-01,  1.0043e+00],\n",
      "        [ 4.1718e+00, -2.9055e+00,  3.3009e-01, -1.3486e+00, -2.2317e-01,\n",
      "          8.9677e-01,  9.6427e-01, -8.4808e-01, -4.2267e-01, -1.2711e+00],\n",
      "        [-1.8189e-01, -1.5307e+00, -6.7573e-01, -6.5912e-02,  3.3622e-01,\n",
      "         -1.0547e-01, -6.7407e-01,  1.6591e+00, -3.9463e-01,  1.0440e+00],\n",
      "        [-5.5721e-01, -2.3482e+00, -2.9332e-01, -7.0030e-01,  2.3284e+00,\n",
      "         -7.3818e-02, -4.7327e-02, -2.3085e-01,  9.1031e-02,  1.5294e+00],\n",
      "        [ 2.6645e+00, -2.2774e+00,  2.3757e-01,  9.9001e-01, -1.2928e+00,\n",
      "          7.3716e-01, -4.0207e-01, -5.6141e-01,  6.8190e-01, -6.0182e-01],\n",
      "        [-1.2487e+00,  1.5441e+00, -2.6233e-01,  3.5219e-02, -5.3996e-01,\n",
      "          2.6153e-01,  2.9822e-01, -4.1663e-01,  3.0533e-01, -4.0438e-01],\n",
      "        [-1.2026e+00, -3.5198e-01, -1.0242e+00,  2.1898e+00, -1.4002e+00,\n",
      "          8.5259e-01, -2.6996e-01,  4.6067e-01,  1.9697e-01, -1.4817e-01],\n",
      "        [-1.0022e+00,  1.1057e+00, -2.7847e-01,  2.7103e-01, -3.1101e-01,\n",
      "          2.4963e-01, -6.7662e-02, -1.4488e-01,  1.7663e-01,  7.6744e-04],\n",
      "        [-1.0225e+00, -9.2968e-01, -7.3663e-01,  2.4126e+00, -2.7747e-01,\n",
      "          1.3068e+00, -3.5567e-01, -1.0556e+00,  6.1580e-01, -1.7662e-01],\n",
      "        [ 1.9235e+00, -1.6051e+00,  6.4330e-01, -1.5785e+00,  8.1722e-01,\n",
      "          3.1203e-01,  1.5875e+00, -8.8763e-01, -3.1239e-01, -2.5910e-01],\n",
      "        [-1.1070e+00, -2.6364e-01,  8.9613e-01, -4.4974e-01, -1.2161e-01,\n",
      "         -5.2019e-01, -1.4966e+00,  1.6475e+00,  6.0686e-01,  6.7150e-01],\n",
      "        [ 5.2634e-01, -1.0259e+00,  2.4432e+00,  2.0044e-01, -8.9452e-01,\n",
      "          1.0837e-01,  2.8275e-01, -6.7288e-01,  1.3430e-01, -1.7180e+00],\n",
      "        [-5.0318e-01, -1.7677e+00,  7.9981e-02, -1.8997e-01,  3.0902e-03,\n",
      "         -3.8091e-01, -6.5698e-01,  2.3203e+00, -1.7345e-01,  9.5230e-01],\n",
      "        [-1.4770e+00,  2.1279e+00, -4.1920e-01, -2.1206e-02, -6.5584e-01,\n",
      "          9.8003e-02,  5.4300e-03, -1.9158e-01,  3.9553e-01, -1.5305e-01],\n",
      "        [ 8.1770e-02,  4.6950e-01,  8.6844e-01,  1.1947e+00, -1.8745e+00,\n",
      "          3.3565e-01,  4.4393e-01, -1.2261e+00,  6.2643e-01, -1.2341e+00],\n",
      "        [-1.5651e+00,  2.8766e+00, -3.3985e-01,  2.2718e-01, -1.3906e+00,\n",
      "         -1.8647e-01, -1.7162e-01, -8.2198e-01,  6.1762e-01, -3.3573e-01],\n",
      "        [-7.5660e-01,  1.5688e+00, -5.1067e-02,  2.7933e-03, -4.7441e-01,\n",
      "         -1.5413e-01,  4.0092e-02, -1.5157e-01,  1.1510e-01, -2.3381e-01],\n",
      "        [-7.7031e-01, -9.0080e-01, -1.4590e-01, -3.8533e-01,  1.7236e-01,\n",
      "         -1.8837e-01, -5.2466e-01,  2.1224e+00, -3.2666e-01,  1.1965e+00],\n",
      "        [-2.1512e+00, -5.9561e-01, -2.9281e-01, -5.0069e-01,  2.0524e+00,\n",
      "         -6.1143e-01, -9.9882e-01,  5.3094e-01,  2.9714e-01,  1.4468e+00],\n",
      "        [-3.8797e-01,  6.9476e-01,  9.0444e-01,  2.0168e-01, -4.0976e-01,\n",
      "         -3.6720e-01,  3.5110e-02, -1.1904e+00,  4.2926e-01, -5.1257e-01],\n",
      "        [-1.3623e+00,  8.4126e-02, -1.6794e-01,  1.1745e+00, -7.2432e-01,\n",
      "          5.8672e-01,  6.2555e-01, -2.1396e-01, -1.4015e-02, -3.7561e-01],\n",
      "        [ 3.9376e-02, -1.4449e+00, -6.1636e-01,  1.4639e+00, -8.0993e-01,\n",
      "          1.3214e+00,  7.3009e-02, -1.3334e+00,  8.2690e-01, -3.3506e-01],\n",
      "        [-1.7426e+00,  2.7945e-01,  6.4327e-02,  7.4652e-01, -2.9379e-01,\n",
      "          5.3560e-01,  2.1792e-01, -5.6625e-02,  1.5956e-01,  2.6557e-01],\n",
      "        [-6.7716e-01, -4.8880e-01,  1.7737e+00, -5.2165e-01,  2.4779e-01,\n",
      "         -6.9347e-01,  3.6929e-01, -3.6797e-01, -1.1066e-01,  1.3200e-01],\n",
      "        [-1.3573e+00, -2.8517e+00, -1.3749e+00, -2.5802e-01,  2.7340e+00,\n",
      "          2.8875e-01, -7.5847e-01,  1.7488e-01,  5.3077e-01,  2.1310e+00],\n",
      "        [-3.8908e-01, -2.1285e+00,  5.0655e-01, -7.9455e-01,  2.2758e+00,\n",
      "         -1.0216e+00,  3.0012e-03,  4.9832e-01, -4.9871e-01,  8.4016e-01],\n",
      "        [-2.5983e-01, -1.3030e+00, -4.8593e-02,  8.6325e-02, -4.7221e-01,\n",
      "          5.1317e-01,  2.0613e+00, -1.1601e+00, -9.6132e-02, -5.9116e-01],\n",
      "        [-1.1720e-01, -9.4064e-01, -1.2920e-01,  1.6319e+00, -4.9696e-01,\n",
      "          4.9631e-01, -4.5961e-01, -3.8885e-01, -1.5239e-01, -1.2369e-01],\n",
      "        [ 3.0612e-01, -1.4457e+00, -1.4073e+00, -2.3550e-02,  5.3934e-01,\n",
      "          1.2431e+00, -9.3230e-02, -1.8083e-01,  2.4808e-02,  3.5450e-01],\n",
      "        [ 3.3956e-01, -7.5078e-01, -4.7195e-01,  9.4525e-01, -6.3493e-02,\n",
      "          6.3882e-01, -2.2431e-01, -5.3732e-01,  2.9347e-01, -4.4428e-01],\n",
      "        [ 1.7780e-01, -4.6952e-01,  1.3992e+00, -2.7395e-01,  6.3868e-01,\n",
      "         -8.3147e-01,  5.9769e-01, -3.9963e-01, -3.6877e-01, -3.6565e-01],\n",
      "        [ 1.5851e+00, -2.2028e+00, -5.2871e-01,  2.3709e-01, -6.9093e-01,\n",
      "          1.1554e+00,  1.5324e-01, -7.4951e-01,  1.3654e+00, -3.4206e-01],\n",
      "        [-2.0840e-01, -2.8296e+00, -5.8440e-02, -6.2296e-01,  2.6403e+00,\n",
      "         -7.1974e-02,  5.8725e-02, -3.3098e-01, -9.2442e-02,  1.0294e+00],\n",
      "        [-8.7165e-01,  2.3965e+00,  5.7212e-02,  2.0674e-01, -9.3463e-01,\n",
      "         -3.7103e-01, -6.5711e-01, -3.1781e-01,  1.7082e-01, -1.0171e-01],\n",
      "        [-4.0398e-01, -1.9824e+00, -9.5373e-01, -9.2979e-01,  1.5228e+00,\n",
      "         -3.5562e-01, -2.7697e-01,  8.5328e-01, -3.3304e-01,  1.9028e+00],\n",
      "        [ 1.7925e-01,  1.3644e-02, -4.6377e-01, -4.2321e-01,  1.7671e-02,\n",
      "          3.9917e-01, -2.9942e-01,  4.4875e-01,  1.2555e-01, -2.4214e-01],\n",
      "        [-1.1947e-01, -1.9882e+00, -7.5367e-01,  3.5631e-01,  2.0137e-01,\n",
      "          4.7329e-02, -3.7960e-01,  2.1395e+00, -6.8571e-01,  5.5875e-01],\n",
      "        [ 1.7711e-01, -8.3187e-01,  1.0021e+00, -1.5840e+00, -1.4318e-01,\n",
      "          7.8233e-02,  5.3232e-01, -9.1804e-01,  1.0463e+00,  3.0909e-01],\n",
      "        [-9.5247e-01, -9.3054e-01, -1.0227e-01, -3.8752e-01,  7.0069e-01,\n",
      "          1.2934e-01,  1.8274e-01, -2.0766e-01,  3.1961e-01,  9.5823e-01],\n",
      "        [-1.0800e+00, -1.1922e-01,  1.0955e+00,  7.7472e-01, -1.5772e-01,\n",
      "         -3.3351e-01, -3.1733e-01, -8.2567e-01,  3.9153e-01,  2.2413e-01],\n",
      "        [-1.1042e+00, -8.9840e-01,  3.4028e-01, -7.0437e-01,  6.7303e-01,\n",
      "         -6.2040e-01, -7.4950e-01,  1.4406e+00,  2.1110e-01,  7.2850e-01],\n",
      "        [-1.3047e+00, -7.1763e-01, -6.8288e-01,  4.5349e-01,  3.3881e-01,\n",
      "          4.9533e-01, -3.3734e-02, -2.5305e-01,  4.1037e-01,  7.3696e-01],\n",
      "        [ 2.5142e-01,  4.2596e-02,  1.0705e+00, -1.7843e-01,  9.8969e-02,\n",
      "         -5.8045e-01,  7.0359e-01,  6.3429e-02, -4.4199e-01, -2.8417e-01],\n",
      "        [-7.1443e-01, -1.8169e+00,  4.6386e-01, -1.1302e+00,  2.2164e+00,\n",
      "         -7.5857e-01, -3.9016e-01,  4.0922e-01, -4.0444e-02,  6.5092e-01],\n",
      "        [-1.5798e+00, -8.3672e-01, -4.1360e-01,  2.6317e+00, -5.8073e-01,\n",
      "          9.7223e-01, -1.0305e+00, -8.2472e-01,  9.9863e-01,  1.3397e-02],\n",
      "        [ 2.4088e+00, -1.4884e+00,  5.6968e-01, -7.9406e-01, -9.3762e-01,\n",
      "          4.1702e-01,  2.2050e-01, -1.0013e-01, -3.1494e-01, -2.7494e-01],\n",
      "        [ 3.7327e-01, -1.2987e+00, -9.2200e-01, -8.0791e-02, -2.2362e-01,\n",
      "         -1.1710e-01, -7.8971e-01,  2.7794e+00, -4.0106e-01,  3.6437e-01],\n",
      "        [ 4.3514e+00, -2.5849e+00,  9.8572e-01,  2.6364e-01, -1.1383e+00,\n",
      "          1.0746e+00, -7.5203e-03, -1.6984e+00,  6.6806e-02, -1.4748e+00],\n",
      "        [ 1.3185e+00, -1.1674e+00,  1.5265e+00,  1.3071e+00, -1.3844e+00,\n",
      "          3.0644e-01,  4.1234e-01, -9.9723e-01, -2.7576e-02, -1.9232e+00],\n",
      "        [-1.7270e+00,  9.2454e-01,  2.6972e-01, -2.0000e-01, -8.4607e-01,\n",
      "         -4.5674e-01, -9.1854e-01,  7.4044e-01,  1.1673e+00,  5.2661e-01],\n",
      "        [-1.4162e+00,  2.3229e+00, -4.2027e-01, -1.9849e-02, -8.9900e-01,\n",
      "          1.0113e-01,  4.3771e-02, -2.5686e-01,  6.2054e-01, -1.8356e-01],\n",
      "        [-1.7078e+00,  4.5957e-01, -7.0610e-01, -5.3277e-01,  5.3795e-01,\n",
      "         -4.6835e-01, -6.4843e-01,  1.7037e+00,  1.0277e-01,  4.4210e-01],\n",
      "        [-5.7245e-01,  1.2515e-02, -4.3074e-01,  2.3151e+00, -1.1492e+00,\n",
      "          9.9494e-01, -4.2157e-01, -1.1234e+00,  3.9406e-01, -7.2969e-01],\n",
      "        [-8.5459e-01, -5.4395e-01,  8.1977e-01, -7.3491e-01, -3.9367e-02,\n",
      "         -4.9936e-01, -1.5135e-01,  1.6242e+00, -1.9654e-01,  5.9666e-01],\n",
      "        [-1.8443e+00,  1.0159e+00, -7.1433e-01,  1.5021e-02, -1.3758e-01,\n",
      "         -7.5815e-02, -6.4557e-01,  3.3274e-01,  6.4703e-01,  6.6914e-01],\n",
      "        [-7.0813e-01, -6.0221e-01, -5.6808e-01, -9.7643e-01, -7.8796e-02,\n",
      "         -3.0494e-01, -1.3650e+00,  3.2806e+00,  1.2283e-01,  6.6320e-01],\n",
      "        [-6.4227e-01, -1.9946e+00, -1.2141e+00, -1.4382e-01,  7.9189e-01,\n",
      "          4.1736e-01, -3.7420e-01,  1.4003e+00, -5.5147e-01,  1.6835e+00],\n",
      "        [ 1.9429e-02, -1.8847e+00,  4.9430e-01, -5.0181e-01, -2.7644e-03,\n",
      "          3.0912e-01,  2.3788e+00, -5.9071e-01, -3.3856e-01,  5.0016e-02],\n",
      "        [-7.1012e-01, -1.4130e+00,  3.7875e+00, -4.9970e-02, -1.6093e-01,\n",
      "         -9.4731e-01,  1.0158e+00, -1.1712e+00,  4.3336e-01, -1.1511e+00],\n",
      "        [-6.8677e-01, -1.9543e+00, -6.6646e-01, -2.5560e-01,  8.0495e-01,\n",
      "         -1.0146e-01, -9.7545e-01,  1.9624e+00, -2.5215e-01,  1.6072e+00],\n",
      "        [-8.0994e-01, -1.7990e-01, -4.9905e-01, -6.9112e-01,  7.2693e-01,\n",
      "          4.2377e-01, -6.2874e-01, -7.2053e-01,  9.6306e-01,  7.9336e-01],\n",
      "        [-1.1185e+00, -2.6435e+00, -8.1576e-01, -6.9642e-02,  3.1193e+00,\n",
      "         -4.7069e-02, -4.7168e-01, -2.9266e-01,  1.8030e-01,  1.3054e+00],\n",
      "        [-1.8581e+00,  5.4879e-01, -2.5100e-01, -6.6273e-01, -1.4987e-01,\n",
      "         -6.7268e-01, -1.1324e+00,  2.9702e+00,  3.2640e-01,  9.7467e-01],\n",
      "        [-6.9919e-02, -1.6209e+00, -1.1570e+00,  1.9028e+00, -2.7330e-02,\n",
      "          1.0324e+00,  5.6920e-01, -3.8860e-01,  5.9866e-02,  6.9562e-02],\n",
      "        [-2.3787e-01, -1.9136e+00,  9.3686e-01, -1.1371e+00,  1.2367e+00,\n",
      "         -3.5620e-01,  2.4237e+00, -1.0777e-01, -6.7492e-01,  2.5551e-01],\n",
      "        [-1.8063e+00,  2.7905e+00,  3.0483e-01, -5.9597e-02, -7.4757e-01,\n",
      "         -4.7041e-01, -4.3956e-01, -4.2648e-01,  4.2024e-01, -5.3734e-01],\n",
      "        [ 3.2397e-01, -9.0337e-01, -2.2345e-01,  2.7618e+00, -1.2981e+00,\n",
      "          7.7245e-01, -1.3209e+00, -4.9923e-01,  9.2542e-01, -6.9888e-01],\n",
      "        [-1.2503e+00, -7.5738e-01,  3.2088e-01, -5.4476e-01,  2.5510e-01,\n",
      "         -2.4853e-01,  2.7387e+00, -1.2144e+00,  1.8371e-01,  2.2073e-01],\n",
      "        [-9.6611e-01, -9.7016e-02,  4.8973e-02, -6.6574e-01,  4.4593e-01,\n",
      "         -1.1902e-01, -2.3293e-01, -1.4320e-01,  5.9946e-01,  4.5967e-01],\n",
      "        [-1.2149e+00, -7.3742e-01, -7.6318e-01,  2.5762e+00, -1.6373e+00,\n",
      "          1.1549e+00, -9.5781e-01,  5.9385e-01,  7.4576e-01,  5.4635e-02],\n",
      "        [-2.3000e+00,  1.7586e+00, -2.9857e-02,  1.6879e-01, -6.0258e-01,\n",
      "          2.3879e-01,  4.8700e-01, -5.8488e-01,  7.1253e-01, -7.3834e-02],\n",
      "        [-9.6512e-01, -5.1818e-01, -3.0605e-01, -1.4346e+00,  2.0466e+00,\n",
      "         -5.9087e-01,  6.3238e-02, -2.4594e-01, -1.1641e-01,  1.1973e+00],\n",
      "        [-1.1636e+00,  5.2039e-01, -2.8920e-01,  3.7720e-01, -2.5086e-01,\n",
      "          3.5018e-01, -3.6440e-02,  3.6371e-02,  3.5797e-01,  2.3387e-01],\n",
      "        [-1.9430e+00,  1.4439e+00, -7.3831e-01, -1.0751e-01, -2.8407e-01,\n",
      "         -2.0926e-01, -6.5760e-02,  5.3166e-01,  2.4130e-01,  4.9409e-01],\n",
      "        [ 8.6863e-01, -1.0543e+00,  8.6295e-01, -9.2360e-01, -2.7576e-01,\n",
      "          5.9334e-01,  1.8673e+00, -1.0477e+00, -1.5663e-01, -6.1283e-01],\n",
      "        [-1.3225e+00, -1.8023e+00, -7.2374e-02, -6.1530e-01,  1.3546e+00,\n",
      "         -9.1294e-01, -4.8872e-01,  8.2421e-01, -5.6696e-02,  2.1109e+00]],\n",
      "       grad_fn=<AddmmBackward>)\n"
     ]
    }
   ],
   "source": [
    "iter_test = 0\n",
    "for images, labels in test_loader:\n",
    "    iter_test += 1\n",
    "    images = images.view(-1, 28*28).requires_grad_()\n",
    "    outputs = model(images)\n",
    "    if iter_test == 1:\n",
    "        print('OUTPUTS')\n",
    "        print(outputs)\n",
    "    _, predicted = torch.max(outputs.data, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Put the first minibatch (100 images) of test dataset into the trained model.\n",
    "And it shows the first data(image) output results (1x10) in which 2.7933 is highest point. It hints the predicted \n",
    "number is 7."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OUTPUTS\n",
      "tensor([-0.3247, -1.1798, -0.4460, -0.0523,  0.1118, -0.3256, -1.1478,  2.7933,\n",
      "        -0.1108,  0.8277], grad_fn=<SliceBackward>)\n"
     ]
    }
   ],
   "source": [
    "iter_test = 0\n",
    "for images, labels in test_loader:\n",
    "    iter_test += 1\n",
    "    images = images.view(-1, 28*28).requires_grad_()\n",
    "    outputs = model(images)\n",
    "    if iter_test == 1:\n",
    "        print('OUTPUTS')\n",
    "        print(outputs[0, :])\n",
    "    _, predicted = torch.max(outputs.data, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OUTPUTS\n",
      "torch.Size([100, 10])\n"
     ]
    }
   ],
   "source": [
    "iter_test = 0\n",
    "for images, labels in test_loader:\n",
    "    iter_test += 1\n",
    "    images = images.view(-1, 28*28).requires_grad_()\n",
    "    outputs = model(images)\n",
    "    if iter_test == 1:\n",
    "        print('OUTPUTS')\n",
    "        print(outputs.size())\n",
    "    _, predicted = torch.max(outputs.data, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PREDICTION\n",
      "torch.Size([100])\n"
     ]
    }
   ],
   "source": [
    "iter_test = 0\n",
    "for images, labels in test_loader:\n",
    "    iter_test += 1\n",
    "    images = images.view(-1, 28*28).requires_grad_()\n",
    "    outputs = model(images)\n",
    "    _, predicted = torch.max(outputs.data, 1)\n",
    "    if iter_test == 1:\n",
    "        print('PREDICTION')\n",
    "        print(predicted.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PREDICTION\n",
      "tensor(7)\n"
     ]
    }
   ],
   "source": [
    "iter_test = 0\n",
    "for images, labels in test_loader:\n",
    "    iter_test += 1\n",
    "    images = images.view(-1, 28*28).requires_grad_()\n",
    "    outputs = model(images)\n",
    "    _, predicted = torch.max(outputs.data, 1)\n",
    "    if iter_test == 1:\n",
    "        print('PREDICTION')\n",
    "        print(predicted[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PREDICTION\n",
      "tensor(7)\n",
      "LABEL SIZE\n",
      "torch.Size([100])\n",
      "LABEL FOR IMAGE 0\n",
      "tensor(7)\n"
     ]
    }
   ],
   "source": [
    "iter_test = 0\n",
    "for images, labels in test_loader:\n",
    "    iter_test += 1\n",
    "    images = images.view(-1, 28*28).requires_grad_()\n",
    "    outputs = model(images)\n",
    "    _, predicted = torch.max(outputs.data, 1)\n",
    "    if iter_test == 1:\n",
    "        print('PREDICTION')\n",
    "        print(predicted[0])\n",
    "        \n",
    "        print('LABEL SIZE')\n",
    "        print(labels.size())\n",
    "        \n",
    "        print('LABEL FOR IMAGE 0')\n",
    "        print(labels[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PREDICTION\n",
      "tensor(2)\n",
      "LABEL SIZE\n",
      "torch.Size([100])\n",
      "LABEL FOR IMAGE 1\n",
      "tensor(2)\n"
     ]
    }
   ],
   "source": [
    "iter_test = 0\n",
    "for images, labels in test_loader:\n",
    "    iter_test += 1\n",
    "    images = images.view(-1, 28*28).requires_grad_()\n",
    "    outputs = model(images)\n",
    "    _, predicted = torch.max(outputs.data, 1)\n",
    "    \n",
    "    if iter_test == 1:\n",
    "        print('PREDICTION')\n",
    "        print(predicted[1])\n",
    "        \n",
    "        print('LABEL SIZE')\n",
    "        print(labels.size())\n",
    "        \n",
    "        print('LABEL FOR IMAGE 1')\n",
    "        print(labels[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "82.42\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "iter_test = 0\n",
    "for images, labels in test_loader:\n",
    "    iter_test += 1\n",
    "    images = images.view(-1, 28*28).requires_grad_()\n",
    "    outputs = model(images)\n",
    "    _, predicted = torch.max(outputs.data, 1)\n",
    "    \n",
    "    # Total number of labels\n",
    "    total += labels.size(0)\n",
    "\n",
    "    # Total correct predictions\n",
    "    correct += (predicted == labels).sum()\n",
    "\n",
    "accuracy = 100 * (correct.item() / total)\n",
    "\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "[1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "[ True  True  True  True  True  True  True  True  True  True]\n",
      "10\n"
     ]
    }
   ],
   "source": [
    "# Explaining .sum() python built-in function\n",
    "# correct += (predicted == labels).sum()\n",
    "import numpy as np\n",
    "a = np.ones((10))\n",
    "print(a)\n",
    "b = np.ones((10))\n",
    "print(b)\n",
    "\n",
    "print(a == b)\n",
    "\n",
    "print((a == b).sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Saving Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_model = False\n",
    "if save_model is True:\n",
    "    # Saves only parameters\n",
    "    torch.save(model.state_dict(), 'awesome_model.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Building a Logistic Regression Model with PyTorch (GPU)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**CPU Version**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 500. Loss: 1.840948224067688. Accuracy: 66.27\n",
      "Iteration: 1000. Loss: 1.5895570516586304. Accuracy: 75.12\n",
      "Iteration: 1500. Loss: 1.298655390739441. Accuracy: 78.09\n",
      "Iteration: 2000. Loss: 1.2521631717681885. Accuracy: 80.08\n",
      "Iteration: 2500. Loss: 1.1440932750701904. Accuracy: 81.51\n",
      "Iteration: 3000. Loss: 0.9545812010765076. Accuracy: 82.24\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as dsets\n",
    "\n",
    "'''\n",
    "STEP 1: LOADING DATASET\n",
    "'''\n",
    "\n",
    "train_dataset = dsets.MNIST(root='./data', \n",
    "                            train=True, \n",
    "                            transform=transforms.ToTensor(),\n",
    "                            download=True)\n",
    "\n",
    "test_dataset = dsets.MNIST(root='./data', \n",
    "                           train=False, \n",
    "                           transform=transforms.ToTensor())\n",
    "\n",
    "'''\n",
    "STEP 2: MAKING DATASET ITERABLE\n",
    "'''\n",
    "\n",
    "batch_size = 100\n",
    "n_iters = 3000\n",
    "num_epochs = n_iters / (len(train_dataset) / batch_size)\n",
    "num_epochs = int(num_epochs)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, \n",
    "                                           batch_size=batch_size, \n",
    "                                           shuffle=True)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_dataset, \n",
    "                                          batch_size=batch_size, \n",
    "                                          shuffle=False)\n",
    "\n",
    "'''\n",
    "STEP 3: CREATE MODEL CLASS\n",
    "'''\n",
    "class LogisticRegressionModel(nn.Module):\n",
    "    def __init__(self, input_size, num_classes):\n",
    "        super(LogisticRegressionModel, self).__init__()\n",
    "        self.linear = nn.Linear(input_dim, output_dim)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        out = self.linear(x)\n",
    "        return out\n",
    "\n",
    "'''\n",
    "STEP 4: INSTANTIATE MODEL CLASS\n",
    "'''\n",
    "input_dim = 28*28\n",
    "output_dim = 10\n",
    "\n",
    "model = LogisticRegressionModel(input_dim, output_dim)\n",
    "\n",
    "'''\n",
    "STEP 5: INSTANTIATE LOSS CLASS\n",
    "'''\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "\n",
    "'''\n",
    "STEP 6: INSTANTIATE OPTIMIZER CLASS\n",
    "'''\n",
    "learning_rate = 0.001\n",
    "\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
    "\n",
    "'''\n",
    "STEP 7: TRAIN THE MODEL\n",
    "'''\n",
    "iter = 0\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "        # Load images as Variable\n",
    "        images = images.view(-1, 28*28).requires_grad_()\n",
    "        labels = labels\n",
    "        \n",
    "        # Clear gradients w.r.t. parameters\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Forward pass to get output/logits\n",
    "        # 100 x 10\n",
    "        outputs = model(images)\n",
    "        \n",
    "        # Calculate Loss: softmax --> cross entropy loss\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        # Getting gradients w.r.t. parameters\n",
    "        loss.backward()\n",
    "        \n",
    "        # Updating parameters\n",
    "        optimizer.step()\n",
    "        \n",
    "        iter += 1\n",
    "        \n",
    "        if iter % 500 == 0:\n",
    "            # Calculate Accuracy         \n",
    "            correct = 0\n",
    "            total = 0\n",
    "            # Iterate through test dataset\n",
    "            for images, labels in test_loader:\n",
    "                # Load images to a Torch Variable\n",
    "                images = images.view(-1, 28*28).requires_grad_()\n",
    "                \n",
    "                # Forward pass only to get logits/output\n",
    "                outputs = model(images)\n",
    "                \n",
    "                # Get predictions from the maximum value\n",
    "                # 100 x 1\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                \n",
    "                # Total number of labels\n",
    "                total += labels.size(0)\n",
    "                \n",
    "                # Total correct predictions\n",
    "                correct += (predicted == labels).sum()\n",
    "            \n",
    "            accuracy = 100 * correct.item() / total\n",
    "            \n",
    "            # Print Loss\n",
    "            print('Iteration: {}. Loss: {}. Accuracy: {}'.format(iter, loss.item(), accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GPU: 2 things must be on GPU\n",
    "- `model`\n",
    "- `variables`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 500. Loss: 1.7876325845718384. Accuracy: 67.12\n",
      "Iteration: 1000. Loss: 1.542566180229187. Accuracy: 74.36\n",
      "Iteration: 1500. Loss: 1.3279670476913452. Accuracy: 77.93\n",
      "Iteration: 2000. Loss: 1.1746045351028442. Accuracy: 80.31\n",
      "Iteration: 2500. Loss: 1.0527358055114746. Accuracy: 81.49\n",
      "Iteration: 3000. Loss: 0.9866024255752563. Accuracy: 82.35\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as dsets\n",
    "\n",
    "'''\n",
    "STEP 1: LOADING DATASET\n",
    "'''\n",
    "\n",
    "train_dataset = dsets.MNIST(root='./data', \n",
    "                            train=True, \n",
    "                            transform=transforms.ToTensor(),\n",
    "                            download=True)\n",
    "\n",
    "test_dataset = dsets.MNIST(root='./data', \n",
    "                           train=False, \n",
    "                           transform=transforms.ToTensor())\n",
    "\n",
    "'''\n",
    "STEP 2: MAKING DATASET ITERABLE\n",
    "'''\n",
    "\n",
    "batch_size = 100\n",
    "n_iters = 3000\n",
    "num_epochs = n_iters / (len(train_dataset) / batch_size)\n",
    "num_epochs = int(num_epochs)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, \n",
    "                                           batch_size=batch_size, \n",
    "                                           shuffle=True)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_dataset, \n",
    "                                          batch_size=batch_size, \n",
    "                                          shuffle=False)\n",
    "\n",
    "'''\n",
    "STEP 3: CREATE MODEL CLASS\n",
    "'''\n",
    "class LogisticRegressionModel(nn.Module):\n",
    "    def __init__(self, input_size, num_classes):\n",
    "        super(LogisticRegressionModel, self).__init__()\n",
    "        self.linear = nn.Linear(input_dim, output_dim)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        out = self.linear(x)\n",
    "        return out\n",
    "\n",
    "'''\n",
    "STEP 4: INSTANTIATE MODEL CLASS\n",
    "'''\n",
    "input_dim = 28*28\n",
    "output_dim = 10\n",
    "\n",
    "model = LogisticRegressionModel(input_dim, output_dim)\n",
    "\n",
    "#######################\n",
    "#  USE GPU FOR MODEL  #\n",
    "#######################\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "'''\n",
    "STEP 5: INSTANTIATE LOSS CLASS\n",
    "'''\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "\n",
    "'''\n",
    "STEP 6: INSTANTIATE OPTIMIZER CLASS\n",
    "'''\n",
    "learning_rate = 0.001\n",
    "\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
    "\n",
    "'''\n",
    "STEP 7: TRAIN THE MODEL\n",
    "'''\n",
    "iter = 0\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "        \n",
    "        #######################\n",
    "        #  USE GPU FOR MODEL  #\n",
    "        #######################\n",
    "        images = images.view(-1, 28*28).requires_grad_().to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        # Clear gradients w.r.t. parameters\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Forward pass to get output/logits\n",
    "        outputs = model(images)\n",
    "        \n",
    "        # Calculate Loss: softmax --> cross entropy loss\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        # Getting gradients w.r.t. parameters\n",
    "        loss.backward()\n",
    "        \n",
    "        # Updating parameters\n",
    "        optimizer.step()\n",
    "        \n",
    "        iter += 1\n",
    "        \n",
    "        if iter % 500 == 0:\n",
    "            # Calculate Accuracy         \n",
    "            correct = 0\n",
    "            total = 0\n",
    "            # Iterate through test dataset\n",
    "            for images, labels in test_loader:\n",
    "                #######################\n",
    "                #  USE GPU FOR MODEL  #\n",
    "                #######################\n",
    "                images = images.view(-1, 28*28).to(device)\n",
    "                \n",
    "                # Forward pass only to get logits/output\n",
    "                outputs = model(images)\n",
    "                \n",
    "                # Get predictions from the maximum value\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                \n",
    "                # Total number of labels\n",
    "                total += labels.size(0)\n",
    "                \n",
    "                #######################\n",
    "                #  USE GPU FOR MODEL  #\n",
    "                #######################\n",
    "                # Total correct predictions\n",
    "                if torch.cuda.is_available():\n",
    "                    correct += (predicted.cpu() == labels.cpu()).sum()\n",
    "                else:\n",
    "                    correct += (predicted == labels).sum()\n",
    "            \n",
    "            accuracy = 100 * correct.item() / total\n",
    "            \n",
    "            # Print Loss\n",
    "            print('Iteration: {}. Loss: {}. Accuracy: {}'.format(iter, loss.item(), accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Logistic regression** basics\n",
    "- **Problems** of **linear regression**\n",
    "- **In-depth** Logistic Regression\n",
    "    1. Get logits\n",
    "    2. Get softmax\n",
    "    3. Get cross-entropy loss\n",
    "- **Aim**: reduce cross-entropy loss\n",
    "- Built a **logistic regression model** in **CPU and GPU**\n",
    "    - Step 1: Load Dataset\n",
    "    - Step 2: Make Dataset Iterable\n",
    "    - Step 3: Create Model Class\n",
    "    - Step 4: Instantiate Model Class\n",
    "    - Step 5: Instantiate Loss Class\n",
    "    - Step 6: Instantiate Optimizer Class\n",
    "    - Step 7: Train Model\n",
    "- Important things to be on **GPU**\n",
    "    - `model`\n",
    "    - `tensors with gradients`"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
